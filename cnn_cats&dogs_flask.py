# -*- coding: utf-8 -*-
"""cnn_cats&dogs_flask

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ncsmBR6zbtAs-3axRdHlz10Bal_NLC6n
"""

import tensorflow as tf
from flask import Flask, request, jsonify, url_for, render_template
import uuid
import os
from tensorflow.keras.models import load_model
import numpy as np
from werkzeug.utils import secure_filename
from PIL import Image, ImageFile
from io import BytesIO
from tensorflow.keras.preprocessing import image
from flask import send_from_directory
import requests
import sys
import glob
import re
import numpy as np
from werkzeug.utils import secure_filename

app = Flask(__name__)
model = load_model("Dog_Cat.h5",compile=True)



@app.route('/')
def index():
    return render_template('index.html')


@app.route('/predict', methods=['GET', 'POST'])
def upload():
	if request.method == 'POST':
        # Get the file from post request
		f = request.files['file']

	    # Save the file to .uploads
		basepath = os.path.dirname(__file__)
		file_path = os.path.join(
		basepath, 'uploads', secure_filename(f.filename))
		f.save(file_path)

		# Make prediction
		img = image.load_img(file_path, target_size=(64, 64))
		# img = cv2.resize(img,(64,64))
		img = np.reshape(img,[1,64,64,3])
		image = tf.cast(img, tf.float32)
		result = (model.predict(img) > 0.5).astype("int32")

		# Process your result for human
		# pred_class = preds.argmax(axis=-1)            # Simple argmax
		# pred_class = decode_predictions(preds, top=1)   # ImageNet Decode
		# result = str(pred_class[0][0][1])               # Convert to string
		if result[0][0] == 1:
			return "DOG"
		else:
			return "CAT"
		# return str(classes)
	return None


if __name__ == '__main__':
    app.run(debug=False)

ALLOWED_EXTENSION  =set(['txt', 'pdf', 'png','jpg','jpeg','gif'])
IMAGE_HEIGHT =64
IMAGE_WIDTH = 64
IMAGE_CHANNELS = 3

def allowed_file(filename):
    return '.' in filename and  filename.rsplit('.',1)[1] in ALLOWED_EXTENSION


app = Flask(__name__)
model = load_model('DVC2.h5',compile=True)

@app.route('/')
def index():
    return render_template('ImageML.html')


# @app.route('/favicon.ico')
# def favicon():
#     return send_from_directory(os.path.join(app.root_path, 'static'),
#                                'favicon.ico', mimetype='image/png')



@app.route('/api/image', methods=['POST'])
def upload_image():
    if 'image' not in request.files:
        return render_template('ImageML.html', prediction='No posted image. Should be attribute named image')
    file = request.files['image']
    
    if file.filename =='':
        return render_template('ImageML.html', prediction = 'You did not select an image')
    
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        print("***"+filename)
        ImageFile.LOAD_TRUNCATED_IMAGES = False
        img = Image.open(BytesIO(file.read()))
        img.load()
        img  = img.resize((IMAGE_WIDTH, IMAGE_HEIGHT))
        img = np.reshape(img,[1,64,64,3])
        image = tf.cast(img, tf.float32)
        # x  = image.img_to_array(img)
        # x = np.expand_dims(x, axis=0)
        # x  = preprocess_input(x)
        cl = model.predict(image)
        # lst =  decode_predictions(pred, top=3)
        
        # items = []
        # for item in lst[0]:
        #     items.append({'name': item[1], 'prob': float(item[2])})
        
        response = (cl>0.5).astype("int32")
        if response[0][0]==1:
            return render_template('ImageML.html', prediction = 'DOG')
        else:
            return render_template('ImageML.html', prediction = 'CAT')


    else:
        return render_template('ImageML.html', prediction = 'Invalid File extension')

if __name__ == '__main__':
    app.run(debug=True, use_reloader=False)







